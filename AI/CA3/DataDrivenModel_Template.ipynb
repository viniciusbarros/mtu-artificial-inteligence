{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CA3 - Data Driven Model\n",
    "- Student Name: **Vinicius Moura Barros**\n",
    "- Student Number: **T00244396**\n",
    "## **Allocation of marks**\n",
    "\n",
    "Stages 1,2,3   Total 30%\n",
    "\n",
    "Ideally your dataset will not need a lot of work. Marks going for the choosing,  training, evaluation and refining of model primarily\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Stage 4,5       Total 60%\n",
    "\n",
    "Choose your model\n",
    "\n",
    "https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html\n",
    "\n",
    "\n",
    "Train and evaluate your model. Refine the model or choose another estimator or approach?\n",
    "\n",
    "Do not overwrite cells and add commentry between iterations.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Stage 6         Total 10%"
   ],
   "metadata": {
    "id": "sgQZcH7afs47"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Stage 0**\n",
    "### Preparation of Environment\n",
    "This section outlines what needs to be installed on the Python environment before this notebook can be executed.\n",
    "Python3 is being used for this project. The following packages need to be installed (e.g.: via `pip install`):\n",
    "- scikit-learn\n",
    "- pandas\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " ### Importing the libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Stage 1**\n",
    "\n",
    "### Background\n",
    "Overwatch is a team-based multiplayer first-person shooter developed and published by Blizzard Entertainment. Overwatch League is the official professional and competitive Overwatch league, where teams compete against each other through the year.\n",
    "\n",
    "A regular official match is composed of a multiple games (or maps), whereas the first team to have 3 games (maps) won, wins the match. Each game is played in a different map, and each map has its own characteristics, which can be advantageous or disadvantageous to a team, depending on their playstyle.\n",
    "\n",
    "The team who loses a map has the chance of choosing what next map they want to play. And this is exactly the type of question that this notebook will try to answer: given a team and this team's adversary, what map should they choose next, in order to increase their chances of winning the match?\n",
    "\n",
    "### Describe Data\n",
    "\n",
    "The dataset chosen for this notebook was a list of previous matches from Overwatch League.\n",
    "All Overwatch League datasets can be found in [Overwatch League official statslab](https://overwatchleague.com/en-us/statslab), and the one used for this notebook can be downloaded exactly from [this URL](https://assets.blz-contentstack.com/v3/assets/blt321317473c90505c/blta8c8b99af29af2be/63f51f804f98c853eaf0983b/match_map_stats.csv.zip).\n",
    "\n",
    "The dataset contains almost 14.000 rows with data about official matches that happened from 11/2018 until 05/2022.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Loading Dataset\n",
    "As the dataset may not be available during the execution of this notebook, a copy can be found in ./data/overwatch_match_map_stats.csv. By loading it from a local disk, it will also make the loading process faster."
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13901 entries, 0 to 13900\n",
      "Data columns (total 25 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   round_start_time              13901 non-null  object \n",
      " 1   round_end_time                13901 non-null  object \n",
      " 2   stage                         13901 non-null  object \n",
      " 3   match_id                      13901 non-null  int64  \n",
      " 4   game_number                   13901 non-null  int64  \n",
      " 5   match_winner                  13901 non-null  object \n",
      " 6   map_winner                    13901 non-null  object \n",
      " 7   map_loser                     13901 non-null  object \n",
      " 8   map_name                      13901 non-null  object \n",
      " 9   map_round                     13901 non-null  int64  \n",
      " 10  winning_team_final_map_score  13901 non-null  int64  \n",
      " 11  losing_team_final_map_score   13901 non-null  int64  \n",
      " 12  control_round_name            4270 non-null   object \n",
      " 13  Attacker                      13901 non-null  object \n",
      " 14  Defender                      13901 non-null  object \n",
      " 15  team_one_name                 13901 non-null  object \n",
      " 16  team_two_name                 13901 non-null  object \n",
      " 17  attacker_payload_distance     13901 non-null  float64\n",
      " 18  defender_payload_distance     13901 non-null  float64\n",
      " 19  attacker_time_banked          13901 non-null  float64\n",
      " 20  defender_time_banked          13901 non-null  float64\n",
      " 21  attacker_control_perecent     4269 non-null   float64\n",
      " 22  defender_control_perecent     4269 non-null   float64\n",
      " 23  attacker_round_end_score      13901 non-null  int64  \n",
      " 24  defender_round_end_score      13901 non-null  int64  \n",
      "dtypes: float64(6), int64(7), object(12)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "DATASET = 'data/overwatch_match_map_stats.csv'\n",
    "df = pd.read_csv(DATASET)\n",
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [
    {
     "data": {
      "text/plain": "  round_start_time  round_end_time          stage  match_id  game_number  \\\n0   01/11/18 00:12  01/11/18 00:20  2018: Stage 1     10223            1   \n1   01/11/18 00:22  01/11/18 00:27  2018: Stage 1     10223            1   \n2   01/11/18 00:34  01/11/18 00:38  2018: Stage 1     10223            2   \n3   01/11/18 00:40  01/11/18 00:44  2018: Stage 1     10223            2   \n4   01/11/18 00:46  01/11/18 00:49  2018: Stage 1     10223            2   \n\n          match_winner           map_winner            map_loser  \\\n0  Los Angeles Valiant  Los Angeles Valiant  San Francisco Shock   \n1  Los Angeles Valiant  Los Angeles Valiant  San Francisco Shock   \n2  Los Angeles Valiant  Los Angeles Valiant  San Francisco Shock   \n3  Los Angeles Valiant  Los Angeles Valiant  San Francisco Shock   \n4  Los Angeles Valiant  Los Angeles Valiant  San Francisco Shock   \n\n           map_name  map_round  ...        team_one_name        team_two_name  \\\n0            Dorado          1  ...  Los Angeles Valiant  San Francisco Shock   \n1            Dorado          2  ...  Los Angeles Valiant  San Francisco Shock   \n2  Temple of Anubis          1  ...  Los Angeles Valiant  San Francisco Shock   \n3  Temple of Anubis          2  ...  Los Angeles Valiant  San Francisco Shock   \n4  Temple of Anubis          3  ...  Los Angeles Valiant  San Francisco Shock   \n\n  attacker_payload_distance defender_payload_distance attacker_time_banked  \\\n0                  75.61505                   0.00000             0.000000   \n1                  75.64960                  75.61505           125.750570   \n2                   0.00000                   0.00000           250.492000   \n3                   0.00000                   0.00000           225.789030   \n4                   0.00000                   0.00000            36.396057   \n\n  defender_time_banked attacker_control_perecent  defender_control_perecent  \\\n0              240.000                       NaN                        NaN   \n1                0.000                       NaN                        NaN   \n2              240.000                       NaN                        NaN   \n3              250.492                       NaN                        NaN   \n4              250.492                       NaN                        NaN   \n\n   attacker_round_end_score  defender_round_end_score  \n0                         2                         0  \n1                         3                         2  \n2                         2                         0  \n3                         2                         2  \n4                         4                         2  \n\n[5 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>round_start_time</th>\n      <th>round_end_time</th>\n      <th>stage</th>\n      <th>match_id</th>\n      <th>game_number</th>\n      <th>match_winner</th>\n      <th>map_winner</th>\n      <th>map_loser</th>\n      <th>map_name</th>\n      <th>map_round</th>\n      <th>...</th>\n      <th>team_one_name</th>\n      <th>team_two_name</th>\n      <th>attacker_payload_distance</th>\n      <th>defender_payload_distance</th>\n      <th>attacker_time_banked</th>\n      <th>defender_time_banked</th>\n      <th>attacker_control_perecent</th>\n      <th>defender_control_perecent</th>\n      <th>attacker_round_end_score</th>\n      <th>defender_round_end_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>01/11/18 00:12</td>\n      <td>01/11/18 00:20</td>\n      <td>2018: Stage 1</td>\n      <td>10223</td>\n      <td>1</td>\n      <td>Los Angeles Valiant</td>\n      <td>Los Angeles Valiant</td>\n      <td>San Francisco Shock</td>\n      <td>Dorado</td>\n      <td>1</td>\n      <td>...</td>\n      <td>Los Angeles Valiant</td>\n      <td>San Francisco Shock</td>\n      <td>75.61505</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>240.000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>01/11/18 00:22</td>\n      <td>01/11/18 00:27</td>\n      <td>2018: Stage 1</td>\n      <td>10223</td>\n      <td>1</td>\n      <td>Los Angeles Valiant</td>\n      <td>Los Angeles Valiant</td>\n      <td>San Francisco Shock</td>\n      <td>Dorado</td>\n      <td>2</td>\n      <td>...</td>\n      <td>Los Angeles Valiant</td>\n      <td>San Francisco Shock</td>\n      <td>75.64960</td>\n      <td>75.61505</td>\n      <td>125.750570</td>\n      <td>0.000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>01/11/18 00:34</td>\n      <td>01/11/18 00:38</td>\n      <td>2018: Stage 1</td>\n      <td>10223</td>\n      <td>2</td>\n      <td>Los Angeles Valiant</td>\n      <td>Los Angeles Valiant</td>\n      <td>San Francisco Shock</td>\n      <td>Temple of Anubis</td>\n      <td>1</td>\n      <td>...</td>\n      <td>Los Angeles Valiant</td>\n      <td>San Francisco Shock</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>250.492000</td>\n      <td>240.000</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>01/11/18 00:40</td>\n      <td>01/11/18 00:44</td>\n      <td>2018: Stage 1</td>\n      <td>10223</td>\n      <td>2</td>\n      <td>Los Angeles Valiant</td>\n      <td>Los Angeles Valiant</td>\n      <td>San Francisco Shock</td>\n      <td>Temple of Anubis</td>\n      <td>2</td>\n      <td>...</td>\n      <td>Los Angeles Valiant</td>\n      <td>San Francisco Shock</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>225.789030</td>\n      <td>250.492</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>2</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>01/11/18 00:46</td>\n      <td>01/11/18 00:49</td>\n      <td>2018: Stage 1</td>\n      <td>10223</td>\n      <td>2</td>\n      <td>Los Angeles Valiant</td>\n      <td>Los Angeles Valiant</td>\n      <td>San Francisco Shock</td>\n      <td>Temple of Anubis</td>\n      <td>3</td>\n      <td>...</td>\n      <td>Los Angeles Valiant</td>\n      <td>San Francisco Shock</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>36.396057</td>\n      <td>250.492</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>"
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Stage 2**\n",
    "\n",
    "### Justification for the property that you would like the model to predict.\n",
    "\n",
    "As described in the Background section, during a game, the team that lost a match have the chance of choosing the next map to be played. This is an important decision as by analyzing historical data, the team might take advantage of existing data about previous match to maximize their chances of winning the next match (and eventually the game).\n",
    "\n",
    "And this is exactly the type of question that this notebook will try to answer: given a team and this team’s adversary, what map should they choose next, in order to increase their chances of winning the match?\n",
    "\n",
    "Based on team_one_name, team_two_name, map_name and map_winner, we will try to predict what map should the team choose next.\n",
    "\n"
   ],
   "metadata": {
    "id": "ZYY0zY7l60al"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Stage 3**\n",
    "\n",
    "### Cleaning the data, linking datasets etc..\n",
    "\n"
   ],
   "metadata": {
    "id": "OeanY09K69Le"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As the main objective is to predict what map to chose, we don't need all the data present in the dataset, so we will filter it to have only the data necessary to train the model.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "df = df[['team_one_name', 'team_two_name', 'map_name', 'map_winner', 'map_loser', 'winning_team_final_map_score',\n",
    "         'losing_team_final_map_score']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "data": {
      "text/plain": "         team_one_name        team_two_name          map_name  \\\n0  Los Angeles Valiant  San Francisco Shock            Dorado   \n1  Los Angeles Valiant  San Francisco Shock            Dorado   \n2  Los Angeles Valiant  San Francisco Shock  Temple of Anubis   \n3  Los Angeles Valiant  San Francisco Shock  Temple of Anubis   \n4  Los Angeles Valiant  San Francisco Shock  Temple of Anubis   \n\n            map_winner            map_loser  winning_team_final_map_score  \\\n0  Los Angeles Valiant  San Francisco Shock                             3   \n1  Los Angeles Valiant  San Francisco Shock                             3   \n2  Los Angeles Valiant  San Francisco Shock                             4   \n3  Los Angeles Valiant  San Francisco Shock                             4   \n4  Los Angeles Valiant  San Francisco Shock                             4   \n\n   losing_team_final_map_score  \n0                            3  \n1                            3  \n2                            4  \n3                            4  \n4                            4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>team_one_name</th>\n      <th>team_two_name</th>\n      <th>map_name</th>\n      <th>map_winner</th>\n      <th>map_loser</th>\n      <th>winning_team_final_map_score</th>\n      <th>losing_team_final_map_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Los Angeles Valiant</td>\n      <td>San Francisco Shock</td>\n      <td>Dorado</td>\n      <td>Los Angeles Valiant</td>\n      <td>San Francisco Shock</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Los Angeles Valiant</td>\n      <td>San Francisco Shock</td>\n      <td>Dorado</td>\n      <td>Los Angeles Valiant</td>\n      <td>San Francisco Shock</td>\n      <td>3</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Los Angeles Valiant</td>\n      <td>San Francisco Shock</td>\n      <td>Temple of Anubis</td>\n      <td>Los Angeles Valiant</td>\n      <td>San Francisco Shock</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Los Angeles Valiant</td>\n      <td>San Francisco Shock</td>\n      <td>Temple of Anubis</td>\n      <td>Los Angeles Valiant</td>\n      <td>San Francisco Shock</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Los Angeles Valiant</td>\n      <td>San Francisco Shock</td>\n      <td>Temple of Anubis</td>\n      <td>Los Angeles Valiant</td>\n      <td>San Francisco Shock</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Also, as the data present in the dataset is mainly strings for team names and map names, we need to convert it to numerical data, so the model can understand it. For this, we will use the LabelEncoder from scikit-learn.\n",
    "\n",
    "The helper functions below will help us to convert the data to numerical data and also to convert it back to the original data whenever needed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "default_dict = defaultdict(LabelEncoder)\n",
    "\n",
    "# we need to convert the categorical data into numerical data so the model can understand it\n",
    "def categorize_df(df: pd.DataFrame):\n",
    "    return df.apply(lambda x: default_dict[x.name].fit_transform(x))\n",
    "\n",
    "def prettify_df(categorized_df: pd.DataFrame):\n",
    "    return categorized_df.apply(lambda x: default_dict[x.name].inverse_transform(x))\n",
    "\n",
    "def get_map_winner_name(map_winner: int):\n",
    "    res = default_dict['map_winner'].inverse_transform([map_winner])\n",
    "    return res.item(0)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Stage 4**\n",
    "Choose and train Estimator.\n",
    "\n",
    "To help finding an estimator, the [Scikit-Learn Choosing the Right Estimator](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html) was used as a guide.\n",
    "\n",
    "The initial estimator chosen for this notebook is the Decision Tree Classifier, however if want to experiment with other classification methods like LogisticRegression and see if one is more accurate than other."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6950 6951 6950 6951\n"
     ]
    }
   ],
   "source": [
    "# These are the features to be taken into consideration when training the model\n",
    "features = ['team_one_name', 'team_two_name', 'map_name']\n",
    "\n",
    "# And target is what we want to be able to predict\n",
    "target = 'map_winner'\n",
    "\n",
    "random_state = 42\n",
    "# percentage of the dataset to be used for testing (the remainder will be used for training)\n",
    "test_size = 0.5\n",
    "\n",
    "categorized_df = categorize_df(df)\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(categorized_df[features], categorized_df[target], test_size=test_size, random_state=random_state)\n",
    "\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### DecisionTreeClassifier\n",
    "Let's create an estimator with the Decision Tree Classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7230614300100705\n"
     ]
    }
   ],
   "source": [
    "# create a decision tree classifier\n",
    "estimator = DecisionTreeClassifier()\n",
    "\n",
    "# fit the model on the training data\n",
    "estimator.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the testing data\n",
    "y_pred = estimator.predict(X_test)\n",
    "\n",
    "# evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "By using the DecisionTreeClassifier, we got an accuracy of more than 72% for the test (not used in the training) data, which is already impressive."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Stage 5**\n",
    "### Evaluate your model and revisit 4...repeat..\n",
    "Now that we have a base-line for comparison (72% of accuracy), let's experiment other estimators and see if we can get a better accuracy with other known classification models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for LogisticRegression: 0.12041432887354338\n",
      "Accuracy for RandomForestClassifier: 0.7170191339375629\n",
      "Accuracy for KNeighborsClassifier: 0.5110056107034959\n",
      "Accuracy for SGDClassifier: 0.10991224284275644\n",
      "Accuracy for SVC: 0.29247590274780605\n"
     ]
    }
   ],
   "source": [
    "estimators_to_be_tested = {\n",
    "    'LogisticRegression': LogisticRegression(max_iter=10000),\n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'KNeighborsClassifier':  KNeighborsClassifier(),\n",
    "    'SGDClassifier': SGDClassifier(),\n",
    "    'SVC': SVC(max_iter=10000),\n",
    "}\n",
    "\n",
    "for name, estimator_instance in estimators_to_be_tested.items():\n",
    "    estimator_instance.fit(X_train, y_train)\n",
    "    temp_y_pred = estimator_instance.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, temp_y_pred)\n",
    "    print(f\"Accuracy for {name}: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can observe on the results above, given the exact same training/test data, the Decision Tree has still better results than the other ones. So, for now, we will keep using the Decision Tree Classifier."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       team_one_name  team_two_name  map_winner  prediction\n",
      "12748             18              9          18          18\n",
      "5577              12             13          13          13\n",
      "688               13              1          13          13\n",
      "12665             15              2          15          15\n",
      "6978               7              3           3           3\n",
      "7246               0             14          14          14\n",
      "3376              19              2          19          19\n",
      "12638             15              6          15          15\n",
      "4438               8              1           8           8\n",
      "9288              13              2           2          13\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_to_check = [random.randint(0,len(df)) for _ in range(10)]\n",
    "\n",
    "to_test = categorized_df.loc[random_to_check]\n",
    "\n",
    "# print(to_test[['team_one_name', 'team_two_name', 'map_winner']])\n",
    "# test_df = pd.DataFrame(df[features])\n",
    "# test_df = categorize_df(test_df)\n",
    "\n",
    "to_test['prediction'] = estimator.predict(to_test[features])\n",
    "\n",
    "print(to_test[['team_one_name', 'team_two_name', 'map_winner', 'prediction']])\n",
    "# for map_winner_id in prediction:\n",
    "#     print(map_winner_id)\n",
    "#     print(f\"Winner is {get_map_winner_name(map_winner_id)}\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "data": {
      "text/plain": "team_one_name                        Paris Eternal\nteam_two_name                   Washington Justice\nmap_name                                   Numbani\nmap_winner                                    draw\nmap_loser                                     draw\nwinning_team_final_map_score                     3\nlosing_team_final_map_score                      3\nName: 9610, dtype: object"
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[9610]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tooling for teams\n",
    "At this stage, we'll provide a tooling for teams to be able to use the model to predict what map to choose next."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Teams Available\n",
      "0 - Los Angeles Valiant\n",
      "1 - Los Angeles Gladiators\n",
      "2 - Shanghai Dragons\n",
      "3 - Seoul Dynasty\n",
      "4 - Dallas Fuel\n",
      "5 - Florida Mayhem\n",
      "6 - London Spitfire\n",
      "7 - Houston Outlaws\n",
      "8 - Philadelphia Fusion\n",
      "9 - New York Excelsior\n",
      "10 - Boston Uprising\n",
      "11 - San Francisco Shock\n",
      "12 - Hangzhou Spark\n",
      "13 - Toronto Defiant\n",
      "14 - Atlanta Reign\n",
      "15 - Chengdu Hunters\n",
      "16 - Guangzhou Charge\n",
      "17 - Paris Eternal\n",
      "18 - Washington Justice\n",
      "19 - Vancouver Titans\n",
      "20 - Vegas Eternal\n",
      "21 - Seoul Infernal\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Teams Available\")\n",
    "teams = df['team_one_name'].unique()\n",
    "for i, name in enumerate(teams):\n",
    "    print(f\"{i} - {name}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your team is Boston Uprising\n",
      "Your opponent team is Chengdu Hunters\n"
     ]
    }
   ],
   "source": [
    "my_team, opponent_team = None, None\n",
    "\n",
    "while my_team is None:\n",
    "    team = int(input(f\"What is your team? (0-{len(teams)})\"))\n",
    "    if 0 <= team < len(teams):\n",
    "        print(f\"Your team is {teams[team]}\")\n",
    "        my_team = team\n",
    "    else:\n",
    "        print(\"Invalid choice, please try again\")\n",
    "\n",
    "while opponent_team is None:\n",
    "    team = int(input(f\"What is your opponent team?(0-{len(teams)}) It must not be {teams[my_team]} \"))\n",
    "    if 0 <= team < len(teams):\n",
    "        print(f\"Your opponent team is {teams[team]}\")\n",
    "        opponent_team = team\n",
    "    else:\n",
    "        print(\"Invalid choice, please try again\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    map_name  team_one_name  team_two_name\n",
      "0          4              0              0\n",
      "1         24              0              0\n",
      "2         11              0              0\n",
      "3         18              0              0\n",
      "4          5              0              0\n",
      "5         12              0              0\n",
      "6         19              0              0\n",
      "7         10              0              0\n",
      "8         14              0              0\n",
      "9         25              0              0\n",
      "10        16              0              0\n",
      "11        13              0              0\n",
      "12        23              0              0\n",
      "13         9              0              0\n",
      "14         7              0              0\n",
      "15        26              0              0\n",
      "16         0              0              0\n",
      "17        22              0              0\n",
      "18         1              0              0\n",
      "19        21              0              0\n",
      "20         8              0              0\n",
      "21        15              0              0\n",
      "22         2              0              0\n",
      "23        17              0              0\n",
      "24         3              0              0\n",
      "25        20              0              0\n",
      "26         6              0              0\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n       1, 0, 1, 0, 0])"
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_maps = list(df['map_name'].unique())\n",
    "\n",
    "\n",
    "dict_data = {\n",
    "             'map_name': unique_maps,\n",
    "              'team_one_name': [teams[my_team]] * len(unique_maps),\n",
    "              'team_two_name': [teams[opponent_team]] * len(unique_maps)\n",
    "             }\n",
    "predict_df = pd.DataFrame(dict_data)\n",
    "\n",
    "categorized_predict_df = categorize_df(predict_df)\n",
    "print(categorized_predict_df)\n",
    "estimator.predict(categorized_predict_df[features])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "tUJT-BYqhNie"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Stage 6**\n",
    "***Present results and Conclusions***\n",
    "\n"
   ],
   "metadata": {
    "id": "4APZXYxS7Yef"
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "joNaHiMMhO6V"
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4,
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
